t testers team
-not generalizable
-identification of soil layers
-last sprint
-baysian network; catboost (what is catboost)
-postprocessing-related things
-coordinate optimization; splitting into regions
-seems like this decreased their accuracy
-WTF is this DAG approach
-combining baysian network with catboost; still needs to be optimized no concrete results yet
-Their model is Catboost with X and Y.
-Nice idea to have the different models as dropdown in the prediction tab.
-Overlay a bar graph with the likelihood of the predictions
-Stacked barchart;
-They have a paid openai api integration for their dashboard
-Counterfactual analysis


Next one
-XGBoost, Viterbi algorithm
-Show feature importances; x and y are important!
-I'll just steal their features
-Present general findings for misclassifications; it's a deconstruction of how X and Y affect the labelling.
-Mons en pevele and Aalbeke
-Infrequent label in CPTs : aalbeke is confused for mons en pevele
-Showing 3 unlabelled CPTs at once
-

First DL
-Hyperpara tuning; XGBoost and LSTM
-XGBoost + LSTM
-LSTM performance optimization
-Two dudes are together in the prediction
-Modular modelling design; model allows disabling of X and 


Our presentation
-LOESS smoothing; maybe we see something nice
-They at the company have used a filter before
-Neurosymbolic AI; rules in decision making
-We invented a neurosymbolic AI 
-Selecting thresholds should be inside the cross validation loop
-CRF slides; idgaf
-Switch axes; the geologists don't like the current layout.
-Prof liked it??
-Rof likes the innovative approaches.
-Pieter Jan also likes binning.
-Prof is really hyping us up
-
Data Science is art and creativity.
