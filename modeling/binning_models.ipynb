{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f695f646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "  EXTRACT_TREND: True\n",
      "  BIN_W: 0.6\n",
      "  SET_SEED: 100\n",
      "  EXTRACT_TREND_TYPE: multiplicative\n",
      "Imported data_processing successfully.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure we can import from the current directory\n",
    "if str(Path.cwd()) not in sys.path:\n",
    "    sys.path.append(str(Path.cwd()))\n",
    "\n",
    "# Import utilities from your existing script\n",
    "try:\n",
    "    import data_processing as dp\n",
    "except ImportError:\n",
    "    # Fallback if running from project root\n",
    "    sys.path.append(\"modeling\")\n",
    "    import data_processing as dp\n",
    "\n",
    "print(\"Imported data_processing successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2288ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_FOLDER = Path(\"../data\")  # Adjust relative path if needed\n",
    "RESULTS_FOLDER = Path(\"../results\")\n",
    "PARQUET_FILENAME = \"vw_cpt_brussels_params_completeset_20250318_remapped.parquet\"\n",
    "\n",
    "BIN_W = 0.6\n",
    "SEED = 42\n",
    "EXTRACT_TREND = True\n",
    "TREND_TYPE = \"additive\"\n",
    "\n",
    "RESULTS_FOLDER.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b09d363",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac9be3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with 267174 rows.\n"
     ]
    }
   ],
   "source": [
    "parquet_path = DATA_FOLDER / PARQUET_FILENAME\n",
    "if not parquet_path.exists():\n",
    "    raise FileNotFoundError(f\"Parquet file not found: {parquet_path}\")\n",
    "\n",
    "cpt_df = pd.read_parquet(parquet_path, engine=\"fastparquet\")\n",
    "cpt_df = cpt_df[~cpt_df[\"lithostrat_id\"].isna()].copy()\n",
    "\n",
    "print(f\"Loaded data with {len(cpt_df)} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb214ca",
   "metadata": {},
   "source": [
    "## 2. Split Train/Test IDs\n",
    "\n",
    "We perform the stratified split on the raw IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7bf6d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train IDs: 199\n",
      "Test IDs:  86\n"
     ]
    }
   ],
   "source": [
    "# Filter rare classes (logic copied from data_processing.py to ensure consistency)\n",
    "litho_counts = (\n",
    "    cpt_df.drop_duplicates(subset=[\"sondering_id\", \"lithostrat_id\"])\n",
    "          .groupby(\"lithostrat_id\", dropna=False)\n",
    "          .size()\n",
    "          .reset_index(name=\"N\")\n",
    ")\n",
    "rare_litho = set(litho_counts.loc[litho_counts[\"N\"] < 5, \"lithostrat_id\"])\n",
    "if rare_litho:\n",
    "    print(f\"Removing rare classes: {rare_litho}\")\n",
    "    cpt_df = cpt_df[~cpt_df[\"lithostrat_id\"].isin(rare_litho)].copy()\n",
    "\n",
    "# Perform Split\n",
    "cpt_unique = cpt_df.drop_duplicates(subset=[\"sondering_id\", \"lithostrat_id\"]).copy()\n",
    "#split_res = dp.group_strat_split(cpt_unique, prop=0.7, tol=0.05, seed=SEED)\n",
    "\n",
    "#train_ids = set(split_res[\"train_ids\"])\n",
    "#test_ids = set(split_res[\"test_ids\"])\n",
    "## load json file split_res.json\n",
    "import json\n",
    "with open(\"../results/split_res.json\", \"r\") as f:\n",
    "    split_res = json.load(f)\n",
    "train_ids = set(split_res[\"train_ids\"])\n",
    "test_ids = set(split_res[\"test_ids\"])\n",
    "\n",
    "\n",
    "print(f\"Train IDs: {len(train_ids)}\")\n",
    "print(f\"Test IDs:  {len(test_ids)}\")\n",
    "\n",
    "# Create separate DataFrames\n",
    "train_raw_df = cpt_df[cpt_df[\"sondering_id\"].isin(train_ids)].copy()\n",
    "test_raw_df = cpt_df[cpt_df[\"sondering_id\"].isin(test_ids)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f7e4c",
   "metadata": {},
   "source": [
    "## 3. Process Data\n",
    "\n",
    "We use the `process_test_train` function from `data_processing` to process each set independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8414493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Training Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mburu/projects/uhasselt/CPT_usecase/modeling/data_processing.py:509: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_trend_and_fill))\n",
      "/home/mburu/miniconda3/lib/python3.11/site-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/mburu/miniconda3/lib/python3.11/site-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/mburu/miniconda3/lib/python3.11/site-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Test Data...\n",
      "   sondering_id  index                                     pkey_sondering  \\\n",
      "0           314   2593  https://www.dov.vlaanderen.be/data/sondering/1...   \n",
      "1           314   2594  https://www.dov.vlaanderen.be/data/sondering/1...   \n",
      "2           314   2595  https://www.dov.vlaanderen.be/data/sondering/1...   \n",
      "3           314   2596  https://www.dov.vlaanderen.be/data/sondering/1...   \n",
      "4           314   2597  https://www.dov.vlaanderen.be/data/sondering/1...   \n",
      "\n",
      "   sondeernummer         x         y  start_sondering_mtaw  \\\n",
      "0  GEO-97/127-S2  153278.2  181734.6                 15.26   \n",
      "1  GEO-97/127-S2  153278.2  181734.6                 15.26   \n",
      "2  GEO-97/127-S2  153278.2  181734.6                 15.26   \n",
      "3  GEO-97/127-S2  153278.2  181734.6                 15.26   \n",
      "4  GEO-97/127-S2  153278.2  181734.6                 15.26   \n",
      "\n",
      "   diepte_sondering_tot  diepte  diepte_mtaw    qc     fs        qtn  \\\n",
      "0                  25.4     1.6        13.66  1.17  0.035  35.894004   \n",
      "1                  25.4     1.7        13.56  1.57  0.033  42.562319   \n",
      "2                  25.4     1.8        13.46  1.43  0.036  38.536991   \n",
      "3                  25.4     1.9        13.36  0.50  0.024  15.678501   \n",
      "4                  25.4     2.0        13.26  1.33  0.023  33.203119   \n",
      "\n",
      "         rf        fr       icn  sbt          ksbt lithostrat_id  \n",
      "0  2.991453  3.058371  2.564340  5.0  1.434000e-07      Quartair  \n",
      "1  2.101911  2.138968  2.406724  5.0  4.321000e-07      Quartair  \n",
      "2  2.517483  2.569226  2.491219  5.0  2.392000e-07      Quartair  \n",
      "3  4.800000  5.111166  2.982185  3.0  7.700000e-09      Quartair  \n",
      "4  1.729323  1.772110  2.440158  5.0  3.419000e-07      Quartair  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mburu/projects/uhasselt/CPT_usecase/modeling/data_processing.py:509: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_trend_and_fill))\n",
      "/home/mburu/miniconda3/lib/python3.11/site-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/mburu/miniconda3/lib/python3.11/site-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/mburu/miniconda3/lib/python3.11/site-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sondering_id   depth_bin     qc_sd     fs_sd     rf_sd    qtn_sd     fr_sd  \\\n",
      "0           314  (1.2, 1.8]  0.020355  0.000424  0.629001  0.768622  0.650116   \n",
      "1           314  (1.8, 2.4]  0.100368  0.001635  1.274885  2.863361  1.375155   \n",
      "2           314  (2.4, 3.0]  0.186748  0.001380  0.365309  4.393847  0.372325   \n",
      "3           314  (3.0, 3.6]  0.106500  0.002760  1.633421  2.370866  2.122284   \n",
      "4           314  (3.6, 4.2]  0.099661  0.002709  1.012828  2.390063  1.117128   \n",
      "\n",
      "   diepte_sd  diepte_mtaw_sd   qc_mean  ...  diepte_whole_q90  \\\n",
      "0   0.070711        0.070711  1.871289  ...             23.02   \n",
      "1   0.216025        0.216025  1.698995  ...             23.02   \n",
      "2   0.187083        0.187083  1.639667  ...             23.02   \n",
      "3   0.158114        0.158114  1.143800  ...             23.02   \n",
      "4   0.216025        0.216025  0.687500  ...             23.02   \n",
      "\n",
      "   diepte_mtaw_whole_q90  diepte_whole_cv  diepte_mtaw_whole_cv  \\\n",
      "0                  11.28          0.51213               3.92827   \n",
      "1                  11.28          0.51213               3.92827   \n",
      "2                  11.28          0.51213               3.92827   \n",
      "3                  11.28          0.51213               3.92827   \n",
      "4                  11.28          0.51213               3.92827   \n",
      "\n",
      "   lithostrat_id  qc_frac_gt20  qc_frac_gt40  qc_count_gt20  qc_count_gt40  \\\n",
      "0       Quartair           0.0           0.0            0.0            0.0   \n",
      "1       Quartair           0.0           0.0            0.0            0.0   \n",
      "2       Quartair           0.0           0.0            0.0            0.0   \n",
      "3       Quartair           0.0           0.0            0.0            0.0   \n",
      "4       Quartair           0.0           0.0            0.0            0.0   \n",
      "\n",
      "   qc_p99  \n",
      "0  1.5660  \n",
      "1  2.2046  \n",
      "2  1.7575  \n",
      "3  1.9080  \n",
      "4  2.0426  \n",
      "\n",
      "[5 rows x 89 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing Training Data...\")\n",
    "train_processed = dp.process_test_train(\n",
    "    cpt_df=train_raw_df, \n",
    "    sondering_ids=list(train_ids), \n",
    "    bin_w=BIN_W, \n",
    "    do_extract_trend=EXTRACT_TREND, \n",
    "    trend_type=TREND_TYPE\n",
    ")\n",
    "\n",
    "print(\"Processing Test Data...\")\n",
    "# print head\n",
    "print(test_raw_df.head())\n",
    "test_processed = dp.process_test_train(\n",
    "    cpt_df=test_raw_df, \n",
    "    sondering_ids=list(test_ids), \n",
    "    bin_w=BIN_W, \n",
    "    do_extract_trend=EXTRACT_TREND, \n",
    "    trend_type=TREND_TYPE\n",
    ")\n",
    "\n",
    "print(test_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f030c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
