{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fe8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# Simple Random forest FOR CPT DATA\n",
    "# ======================================================\n",
    "# \n",
    "# Purpose: Predict lithostratigraphic units from CPT data using CRF\n",
    "# ======================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce42a155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: C:\\Users\\dorothy.chepkoech\\Documents\\MSC_2026\\Project_DataScience\\Data\\remapped.parquet\n",
      "Raw shape: (1220548, 19)\n",
      "Known before imputation: (236393, 19)\n",
      "Known after imputation: (236393, 19)\n",
      "Known after label cleaning: (236393, 19)\n",
      "Feature matrix shape: (236393, 29)\n",
      "Train rows: 160363  Test rows: 76030\n",
      "\n",
      "Random Forest accuracy: 0.534\n",
      "\n",
      "Classification report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Aalbeke       0.49      0.43      0.46      4473\n",
      "                Asse       0.28      0.28      0.28      1609\n",
      "          Bolderberg       0.03      0.00      0.01      1551\n",
      "             Brussel       0.54      0.72      0.62     13133\n",
      "               Diest       0.51      0.34      0.41      2572\n",
      "           Kwatrecht       0.08      0.10      0.09      1103\n",
      "                Lede       0.37      0.33      0.35      5330\n",
      "           Merelbeke       0.32      0.32      0.32       326\n",
      "      Mons_en_Pevele       0.35      0.34      0.34      7288\n",
      "        Mont_Panisel       0.49      0.56      0.52      8095\n",
      "            Quartair       0.72      0.73      0.72     21828\n",
      "Sint_Huibrechts_Hern       0.78      0.39      0.52      3945\n",
      "               Ursel       0.36      0.21      0.26      1520\n",
      "              Wemmel       0.35      0.37      0.36      3257\n",
      "\n",
      "            accuracy                           0.53     76030\n",
      "           macro avg       0.41      0.36      0.38     76030\n",
      "        weighted avg       0.53      0.53      0.52     76030\n",
      "\n",
      "\n",
      "Top 15 features by importance:\n",
      "diepte            0.162947\n",
      "depth_norm        0.150140\n",
      "qc                0.108814\n",
      "qtn               0.092387\n",
      "fs                0.088814\n",
      "qtn_fr_ratio      0.060954\n",
      "icn               0.058420\n",
      "qc_fs_ratio       0.055886\n",
      "rf                0.055784\n",
      "ksbt              0.055071\n",
      "fr                0.053155\n",
      "is_clay_like      0.007732\n",
      "qc_bin_qc_low     0.007335\n",
      "qc_bin_qc_med     0.005894\n",
      "qc_bin_qc_high    0.005605\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 1. Imports\n",
    "# =========================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# =========================================\n",
    "# 2. Read data\n",
    "# =========================================\n",
    "home = Path.home()\n",
    "path_to_parquet = home / \"Documents\" / \"MSC_2026\" / \"Project_DataScience\" / \"Data\" / \"remapped.parquet\"\n",
    "\n",
    "print(\"Reading:\", path_to_parquet)\n",
    "df = pd.read_parquet(path_to_parquet)\n",
    "print(\"Raw shape:\", df.shape)\n",
    "\n",
    "# =========================================\n",
    "# 3. Basic config\n",
    "# =========================================\n",
    "cpt_col   = \"sondeernummer\"\n",
    "depth_col = \"diepte\"\n",
    "label_col = \"lithostrat_id\"\n",
    "\n",
    "segments_oi = [\n",
    "    \"Quartair\",\n",
    "    \"Diest\",\n",
    "    \"Bolderberg\",\n",
    "    \"Sint_Huibrechts_Hern\",\n",
    "    \"Ursel\",\n",
    "    \"Asse\",\n",
    "    \"Wemmel\",\n",
    "    \"Lede\",\n",
    "    \"Brussel\",\n",
    "    \"Merelbeke\",\n",
    "    \"Kwatrecht\",\n",
    "    \"Mont_Panisel\",\n",
    "    \"Aalbeke\",\n",
    "    \"Mons_en_Pevele\",\n",
    "]\n",
    "\n",
    "invalid_labels = {\"\", \"none\", \"nan\", \"onbekend\"}\n",
    "\n",
    "# =========================================\n",
    "# 4. Imputation function (same as before)\n",
    "# =========================================\n",
    "def impute_params(df_in: pd.DataFrame, overwrite: bool = False) -> pd.DataFrame:\n",
    "    df = df_in.copy()\n",
    "\n",
    "    # icn\n",
    "    mask_icn = df[\"icn\"].isna() if not overwrite else np.ones(len(df), dtype=bool)\n",
    "    valid_icn = mask_icn & df[\"qtn\"].gt(0) & df[\"fr\"].gt(0)\n",
    "\n",
    "    icn_new = np.sqrt(\n",
    "        (3.47 - np.log10(df.loc[valid_icn, \"qtn\"])) ** 2\n",
    "        + (np.log10(df.loc[valid_icn, \"fr\"]) + 1.22) ** 2\n",
    "    )\n",
    "    df.loc[valid_icn, \"icn\"] = icn_new\n",
    "\n",
    "    # sbt from icn\n",
    "    def sbt_from_icn(icn):\n",
    "        if pd.isna(icn):\n",
    "            return np.nan\n",
    "        if icn < 1.31:\n",
    "            return 1\n",
    "        elif icn < 2.05:\n",
    "            return 2\n",
    "        elif icn < 2.60:\n",
    "            return 3\n",
    "        elif icn < 2.95:\n",
    "            return 4\n",
    "        elif icn < 3.60:\n",
    "            return 5\n",
    "        else:\n",
    "            return 6\n",
    "\n",
    "    mask_sbt = df[\"sbt\"].isna() if not overwrite else np.ones(len(df), dtype=bool)\n",
    "    df.loc[mask_sbt, \"sbt\"] = df.loc[mask_sbt, \"icn\"].apply(sbt_from_icn)\n",
    "\n",
    "    # ksbt from icn\n",
    "    df[\"ksbt\"] = pd.to_numeric(df[\"ksbt\"], errors=\"coerce\")\n",
    "\n",
    "    def ksbt_from_icn(icn):\n",
    "        if pd.isna(icn):\n",
    "            return np.nan\n",
    "        if 1.0 < icn <= 3.27:\n",
    "            return 10 ** (0.952 - 3.04 * icn)\n",
    "        elif icn > 3.27:\n",
    "            return 10 ** (-4.52 - 1.37 * icn)\n",
    "\n",
    "    mask_ksbt = df[\"ksbt\"].isna() if not overwrite else np.ones(len(df), dtype=bool)\n",
    "    df.loc[mask_ksbt, \"ksbt\"] = df.loc[mask_ksbt, \"icn\"].apply(ksbt_from_icn)\n",
    "\n",
    "    return df\n",
    "\n",
    "# =========================================\n",
    "# 5. Filter to segments of interest and clean labels\n",
    "# =========================================\n",
    "df_known = df[df[label_col].isin(segments_oi)].copy()\n",
    "print(\"Known before imputation:\", df_known.shape)\n",
    "\n",
    "df_known = impute_params(df_known, overwrite=False)\n",
    "print(\"Known after imputation:\", df_known.shape)\n",
    "\n",
    "df_known = df_known[~df_known[label_col].isin(invalid_labels)]\n",
    "df_known = df_known.dropna(subset=[label_col])\n",
    "print(\"Known after label cleaning:\", df_known.shape)\n",
    "\n",
    "# sort by CPT and depth (not strictly needed for RF, but nice to keep)\n",
    "df_known = df_known.sort_values([cpt_col, depth_col])\n",
    "\n",
    "# =========================================\n",
    "# 6. Feature engineering (same ideas as CRF)\n",
    "# =========================================\n",
    "\n",
    "# depth normalization per CPT\n",
    "df_known[\"max_depth_cpt\"] = df_known.groupby(cpt_col)[depth_col].transform(\"max\")\n",
    "df_known[\"depth_norm\"] = df_known[depth_col] / df_known[\"max_depth_cpt\"]\n",
    "\n",
    "# qc / Rf bins\n",
    "def add_qc_rf_bins(df_in):\n",
    "    df = df_in.copy()\n",
    "    df[\"qc_bin\"] = pd.cut(\n",
    "        df[\"qc\"],\n",
    "        bins=[-np.inf, 2, 5, 10, 20, np.inf],\n",
    "        labels=[\"qc_vlow\", \"qc_low\", \"qc_med\", \"qc_high\", \"qc_vhigh\"],\n",
    "    )\n",
    "    df[\"rf_bin\"] = pd.cut(\n",
    "        df[\"fr\"],\n",
    "        bins=[-np.inf, 1, 2, 4, 6, np.inf],\n",
    "        labels=[\"rf_vlow\", \"rf_low\", \"rf_med\", \"rf_high\", \"rf_vhigh\"],\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df_known = add_qc_rf_bins(df_known)\n",
    "\n",
    "# ratios\n",
    "eps = 1e-6\n",
    "df_known[\"qc_fs_ratio\"]  = df_known[\"qc\"]  / (df_known[\"fs\"].abs()  + eps)\n",
    "df_known[\"qtn_fr_ratio\"] = df_known[\"qtn\"] / (df_known[\"fr\"].abs() + eps)\n",
    "\n",
    "# expert flags\n",
    "df_known[\"is_clay_like\"] = ((df_known[\"qc\"] < 4) & (df_known[\"fr\"] > 3)).astype(int)\n",
    "df_known[\"is_merelbeke_like\"] = ((df_known[\"qc\"] < 2) & (df_known[\"fr\"] > 5)).astype(int)\n",
    "\n",
    "# =========================================\n",
    "# 7. Build feature matrix X and target y\n",
    "# =========================================\n",
    "\n",
    "# numeric features\n",
    "num_feats = [\n",
    "    \"qc\", \"fs\", \"rf\", \"qtn\", \"fr\", \"icn\", \"ksbt\",\n",
    "    depth_col, \"depth_norm\",\n",
    "    \"qc_fs_ratio\", \"qtn_fr_ratio\",\n",
    "    \"is_clay_like\", \"is_merelbeke_like\",\n",
    "]\n",
    "\n",
    "# categorical features (one-hot)\n",
    "cat_feats = [\"sbt\", \"qc_bin\", \"rf_bin\"]\n",
    "\n",
    "# keep rows that have all required columns\n",
    "needed_cols = num_feats + cat_feats + [label_col, cpt_col]\n",
    "df_model = df_known[needed_cols].dropna(subset=num_feats)  # allow NaNs in cats, they become their own category\n",
    "\n",
    "# one-hot encode categorical vars\n",
    "X = pd.get_dummies(df_model[num_feats + cat_feats], columns=cat_feats)\n",
    "y = df_model[label_col]\n",
    "groups = df_model[cpt_col]   # for CPT-based split\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "\n",
    "# =========================================\n",
    "# 8. Train/test split by CPT (no leakage)\n",
    "# =========================================\n",
    "\n",
    "unique_cpts = groups.unique()\n",
    "train_cpts, test_cpts = train_test_split(\n",
    "    unique_cpts, test_size=0.3, random_state=22\n",
    ")\n",
    "\n",
    "train_mask = groups.isin(train_cpts)\n",
    "test_mask  = groups.isin(test_cpts)\n",
    "\n",
    "X_train, X_test = X[train_mask], X[test_mask]\n",
    "y_train, y_test = y[train_mask], y[test_mask]\n",
    "\n",
    "print(\"Train rows:\", X_train.shape[0], \" Test rows:\", X_test.shape[0])\n",
    "\n",
    "# =========================================\n",
    "# 9. Random Forest training\n",
    "# =========================================\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=22,\n",
    "    class_weight=\"balanced\"   # handle class imbalance a bit\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# =========================================\n",
    "# 10. Evaluation: accuracy + report\n",
    "# =========================================\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nRandom Forest accuracy: {acc:.3f}\\n\")\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# (optional) Show top 15 features by importance â€“ nice for your slides\n",
    "importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "print(\"\\nTop 15 features by importance:\")\n",
    "print(importances.sort_values(ascending=False).head(15))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "APPY2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
