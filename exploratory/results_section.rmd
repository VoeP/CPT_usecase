---
title: "Model Results Analysis"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  fig.width = 6.3,
  fig.height = 4,
  dpi = 500
)
```

### Binning model
```{r}
library(dplyr)
library(ggplot2)
library(forcats)
library(ggrepel)  # for nicer text labels on the scatter plot

# -------------------------------------------------------------------
# 1. Enter the classification report as a data frame
# -------------------------------------------------------------------



metrics <-  tribble(
  ~layer,                 ~precision, ~recall, ~f1,   ~support,
  "Aalbeke",                 0.62,      0.61,   0.62,   3439,
  "Asse",                    0.69,      0.56,   0.61,   2542,
  "Bolderberg",              0.00,      0.00,   0.00,    978,
  "Brussel",                 0.77,      0.83,   0.80,  13906,
  "Diest",                   1.00,      0.73,   0.84,   1106,
  "Kwatrecht",               0.35,      0.34,   0.35,    962,
  "Lede",                    0.73,      0.78,   0.75,   8807,
  "Merelbeke",               0.54,      0.41,   0.47,    433,
  "Mons_en_Pevele",          0.65,      0.74,   0.69,   6055,
  "Mont_Panisel",            0.75,      0.82,   0.78,   7129,
  "Quartair",                0.85,      0.82,   0.83,  24071,
  "Sint_Huibrechts_Hern",    0.61,      0.37,   0.46,   2294,
  "Ursel",                   0.42,      0.47,   0.45,   1642,
  "Wemmel",                  0.59,      0.62,   0.60,   4444
)




# -------------------------------------------------------------------
# 2. Define “difficulty” based on F1 (you can tweak the cut–offs)
#    - easy   : F1 >= 0.75
#    - medium : 0.60 <= F1 < 0.75
#    - hard   : F1 < 0.60
# -------------------------------------------------------------------
metrics <- metrics %>%
  mutate(
    difficulty = case_when(
      f1 >= 0.75 ~ "easy",
      f1 >= 0.60 ~ "medium",
      TRUE       ~ "hard"
    ),
    difficulty = factor(difficulty, levels = c("easy", "medium", "hard")),
    # order layers by F1 so the plot reads from hardest (bottom) to easiest (top)
    layer = fct_reorder(layer, f1)
  )

# -------------------------------------------------------------------
# 3. Bar plot: which rocks are easy vs hard to predict?
# -------------------------------------------------------------------
p_f1 <- ggplot(metrics, aes(x = layer, y = f1, fill = difficulty)) +
  geom_col() +
  geom_hline(yintercept = 0.60, linetype = "dashed") +
  geom_hline(yintercept = 0.75, linetype = "dashed") +
  coord_flip() +
  scale_y_continuous(limits = c(0, 1), expand = expansion(mult = c(0, 0.05))) +
  labs(
    x = "Layer / Rock type",
    y = "F1-score",
    fill = "Difficulty",
    title = "Random Forest performance by layer",
    subtitle = "Higher F1 = easier to predict; dashed lines at 0.60 and 0.75"
  ) +
  theme_minimal()

p_f1
```



```{r}
p_pr <- ggplot(metrics,
               aes(x = recall, y = precision,
                   colour = difficulty, size = support, label = layer)) +
  geom_point(alpha = 0.8) +
  geom_abline(slope = 1, intercept = 0, linetype = "dotted") +
  ggrepel::geom_text_repel(show.legend = FALSE, max.overlaps = 100) +
  scale_x_continuous(limits = c(0, 1), expand = expansion(mult = 0.02)) +
  scale_y_continuous(limits = c(0, 1), expand = expansion(mult = 0.02)) +
  labs(
    x = "Recall",
    y = "Precision",
    colour = "Difficulty",
    size = "Support (n)",
    title = "Precision–recall trade-off by layer",
    subtitle = "Big, high points = well-supported & easy; small, low points = hard"
  ) +
  theme_minimal()

p_pr

```



```{r}

library(dplyr)
library(ggplot2)
library(ggrepel)

# 1. (Assumes 'metrics' already exists from previous code.)

# 2. Correlation between F1 ("accuracy") and sample size
cor_f1_support <- cor(metrics$f1, metrics$support)
cor_f1_support
# You can report this number in the text, e.g.
# "Correlation between F1-score and support = ..."

# 3. Scatter plot: F1 vs support
p_f1_support <- ggplot(metrics,
                       aes(x = support, y = f1,
                           colour = difficulty, label = layer)) +
  geom_point(aes(size = support), alpha = 0.8) +
  geom_smooth(method = "lm", se = FALSE, linetype = "dashed") +
  ggrepel::geom_text_repel(show.legend = FALSE, max.overlaps = 100) +
  scale_x_continuous(trans = "log10",
                     breaks = c(10, 20, 50, 100, 200, 500, 1000)) +
  scale_y_continuous(limits = c(0, 1), expand = expansion(mult = 0.02)) +
  labs(
    x = "Support (log10 scale)",
    y = "F1-score (per-class accuracy proxy)",
    colour = "Difficulty",
    size = "Support (n)",
    title = "Relationship between sample size and predictive performance",
    subtitle = paste0("Dashed line = linear fit; cor(F1, support) = ",
                      round(cor_f1_support, 2))
  ) +
  theme_minimal()

p_f1_support
```

### RF 

```{r}
# -------------------------------------------------------------------
# 1. Metrics table for RF on full Voep data
# -------------------------------------------------------------------
rf_voep <- tribble(
  ~layer,             ~precision, ~recall, ~f1,  ~support,
  "Aalbeke",              0.78,      0.31,  0.45,   933,
  "Asse",                 0.64,      0.45,  0.53,  1130,
  "Bolderberg",           0.25,      0.37,  0.30,   140,
  "Brussel",              0.67,      0.64,  0.65,  3142,
  "Diest",                0.00,      0.00,  0.00,     0,
  "Kwatrecht",            0.81,      0.49,  0.61,   593,
  "Lede",                 0.48,      0.64,  0.55,  2617,
  "Merelbeke",            0.00,      0.00,  0.00,    16,
  "Mons_en_Pevele",       0.70,      0.24,  0.36,  2348,
  "Mont_Panisel",         0.50,      0.91,  0.64,  1787,
  "Quartair",             0.83,      0.87,  0.85,  7854,
  "Ursel",                0.85,      0.80,  0.83,  1138,
  "Wemmel",               0.54,      0.57,  0.55,  1367
)

# -------------------------------------------------------------------
# 2. Difficulty labels and ordering by F1
# -------------------------------------------------------------------
rf_voep <- rf_voep %>%
  mutate(
    difficulty = case_when(
      f1 >= 0.75 ~ "easy",
      f1 >= 0.60 ~ "medium",
      TRUE       ~ "hard"
    ),
    difficulty = factor(difficulty, levels = c("easy", "medium", "hard")),
    layer = fct_reorder(layer, f1)  # order by F1
  )

# -------------------------------------------------------------------
# 3. Bar plot of F1 by layer (easy vs hard)
# -------------------------------------------------------------------
p_voep_f1 <- ggplot(rf_voep, aes(x = layer, y = f1, fill = difficulty)) +
  geom_col() +
  geom_hline(yintercept = 0.60, linetype = "dashed") +
  geom_hline(yintercept = 0.75, linetype = "dashed") +
  coord_flip() +
  scale_y_continuous(limits = c(0, 1), expand = expansion(mult = c(0, 0.05))) +
  labs(
    x = "Layer / Rock type",
    y = "F1-score",
    fill = "Difficulty",
    title = "Random Forest (Voep): performance by layer",
    subtitle = "Higher F1 = easier to predict; dashed lines at 0.60 and 0.75"
  ) +
  theme_minimal()

p_voep_f1

# -------------------------------------------------------------------
# 4. F1 vs support (sample size) – correlation plot
#    Drop Diest (support = 0) for log10 scale
# -------------------------------------------------------------------
rf_voep_plot <- rf_voep %>% filter(support > 0)

cor_voep_f1_support <- cor(rf_voep_plot$f1, rf_voep_plot$support)

p_voep_f1_support <- ggplot(rf_voep_plot,
                            aes(x = support, y = f1,
                                colour = difficulty,
                                size = support,
                                label = layer)) +
  geom_point(alpha = 0.8) +
  geom_smooth(method = "lm", se = FALSE, linetype = "dashed") +
  ggrepel::geom_text_repel(show.legend = FALSE, max.overlaps = 100) +
  scale_x_continuous(trans = "log10",
                     breaks = c(10, 20, 50, 100, 200, 500, 1000, 5000, 10000)) +
  scale_y_continuous(limits = c(0, 1), expand = expansion(mult = 0.02)) +
  labs(
    x = "Support (log10 scale)",
    y = "F1-score (per-class accuracy proxy)",
    colour = "Difficulty",
    size = "Support (n)",
    title = "RF (Voep): relationship between sample size and predictive performance",
    subtitle = paste0("Dashed line = linear fit; cor(F1, support) = ",
                      round(cor_voep_f1_support, 2))
  ) +
  theme_minimal()

p_voep_f1_support
```

### CRM model

```{r}

# ----------------------------------------------------------
# 1. CRM model metrics table
# ----------------------------------------------------------
crm_model <- tribble(
  ~layer,                 ~precision, ~recall, ~f1,   ~support,
  "Aalbeke",                 0.380,    0.266,  0.313,   4473,
  "Asse",                    0.408,    0.245,  0.307,   1609,
  "Bolderberg",              0.000,    0.000,  0.000,   1551,
  "Brussel",                 0.553,    0.533,  0.543,  13133,
  "Diest",                   0.314,    0.302,  0.308,   2572,
  "Kwatrecht",               0.000,    0.000,  0.000,   1103,
  "Lede",                    0.218,    0.220,  0.219,   5330,
  "Merelbeke",               0.000,    0.000,  0.000,    326,
  "Mons_en_Pevele",          0.164,    0.328,  0.219,   7288,
  "Mont_Panisel",            0.429,    0.451,  0.439,   8095,
  "Quartair",                0.728,    0.734,  0.731,  21828,
  "Sint_Huibrechts_Hern",    0.103,    0.071,  0.084,   3945,
  "Ursel",                   0.245,    0.037,  0.064,   1520,
  "Wemmel",                  0.394,    0.392,  0.393,   3257
)

# ----------------------------------------------------------
# 2. Difficulty labels + ordering by F1
#    (same thresholds as before)
# ----------------------------------------------------------
crm_model <- crm_model %>%
  mutate(
    difficulty = case_when(
      f1 >= 0.75 ~ "easy",
      f1 >= 0.60 ~ "medium",
      TRUE       ~ "hard"
    ),
    difficulty = factor(difficulty, levels = c("easy", "medium", "hard")),
    layer = fct_reorder(layer, f1)   # order by F1
  )

# ----------------------------------------------------------
# 3. Bar plot: which layers are easy / hard for the CRM model?
# ----------------------------------------------------------
p_crm_f1 <- ggplot(crm_model, aes(x = layer, y = f1, fill = difficulty)) +
  geom_col() +
  geom_hline(yintercept = 0.60, linetype = "dashed") +
  geom_hline(yintercept = 0.75, linetype = "dashed") +
  coord_flip() +
  scale_y_continuous(limits = c(0, 1), expand = expansion(mult = c(0, 0.05))) +
  labs(
    x = "Layer / Rock type",
    y = "F1-score",
    fill = "Difficulty",
    title = "CRM model: performance by layer",
    subtitle = "Higher F1 = easier to predict; dashed lines at 0.60 and 0.75"
  ) +
  theme_minimal()

p_crm_f1

# ----------------------------------------------------------
# 4. F1 vs support: does more data help the CRM model?
# ----------------------------------------------------------
cor_crm_f1_support <- cor(crm_model$f1, crm_model$support)

p_crm_f1_support <- ggplot(crm_model,
                           aes(x = support, y = f1,
                               colour = difficulty,
                               size = support,
                               label = layer)) +
  geom_point(alpha = 0.8) +
  geom_smooth(method = "lm", se = FALSE, linetype = "dashed") +
  ggrepel::geom_text_repel(show.legend = FALSE, max.overlaps = 100) +
  scale_x_continuous(
    trans = "log10",
    breaks = c(100, 300, 1000, 3000, 10000, 30000)
  ) +
  scale_y_continuous(limits = c(0, 1), expand = expansion(mult = 0.02)) +
  labs(
    x = "Support (log10 scale)",
    y = "F1-score (per-class accuracy proxy)",
    colour = "Difficulty",
    size   = "Support (n)",
    title = "CRM model: sample size vs predictive performance",
    subtitle = paste0("Dashed line = linear fit; cor(F1, support) = ",
                      round(cor_crm_f1_support, 2))
  ) +
  theme_minimal()

p_crm_f1_support
```